# GPU Embedder Serverless Configuration

# Enable GPU inference
ONNX_USE_GPU=true

# Model path (relative to /app in container)
MODEL_PATH=/app/models/minilm-l6

# CUDA device (default: 0)
CUDA_VISIBLE_DEVICES=0

# Logging level
LOG_LEVEL=INFO
